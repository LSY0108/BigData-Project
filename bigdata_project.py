# -*- coding: utf-8 -*-
"""BigData-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wzA69UpyRVHiiRxgoF9hNWdYD1nTiw88

**ê¸°í›„ ë³€í™”ì— ë”°ë¥¸ ìŒ€ ìƒì‚°ëŸ‰ ë¶„ì„ ë° ì˜ˆì¸¡**<br>
(3-A)202244035<br>
ì´ìŠ¹ì˜ˆ
"""

# ë‹¨ê³„ 1: í°íŠ¸ ì„¤ì¹˜
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

!apt-get -qq -y install fonts-nanum > /dev/null

fe = fm.FontEntry(
    fname=r'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf', # ttf íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ë¡œ
    name='NanumGothic')                        # ì´ í°íŠ¸ì˜ ì›í•˜ëŠ” ì´ë¦„ ì„¤ì •
fm.fontManager.ttflist.insert(0, fe)              # Matplotlibì— í°íŠ¸ ì¶”ê°€
plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'}) # í°íŠ¸ ì„¤ì¹˜

# ë‹¨ê³„ 2: ëŸ°íƒ€ì„ ì¬ì‹œì‘
import os
os.kill(os.getpid(), 9)

# ë‹¨ê³„ 3: í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.font_manager as fm

# ë§ˆì´ë„ˆìŠ¤ í‘œì‹œ ë¬¸ì œ
mpl.rcParams['axes.unicode_minus'] = False

# í•œê¸€ í°íŠ¸ ì„¤ì •
fe = fm.FontEntry(
    fname=r'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf', # ttf íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ë¡œ
    name='NanumGothic')                        # ì´ í°íŠ¸ì˜ ì›í•˜ëŠ” ì´ë¦„ ì„¤ì •
fm.fontManager.ttflist.insert(0, fe)              # Matplotlibì— í°íŠ¸ ì¶”ê°€
plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'}) # í°íŠ¸ ì„¤ì¹˜

import pandas as pd
import numpy as np
from typing import List, Optional, Dict, Tuple
from pathlib import Path
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')

class DataProcessor:
    """ìŒ€ ìƒì‚°ëŸ‰ê³¼ ê¸°í›„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    1. ìŒ€ ìƒì‚°ëŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ ë° êµ¬ì¡°í™”
    2. ê¸°í›„ ë°ì´í„°(ì—°ê°„/ì›”ê°„) ì „ì²˜ë¦¬ ë° ì •ê·œí™”
    3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ë°ì´í„° ë³´ê°„
    4. ì§€ì—­ë³„ ë°ì´í„° ë§¤í•‘ ë° í•„í„°ë§

    ì£¼ìš” ì²˜ë¦¬ ê³¼ì •:
    1. Excel/CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ë°ì´í„° ì •ê·œí™”
    3. ì§€ì—­ë³„ ë°ì´í„° ë§¤í•‘ ë° í†µê³„ ê³„ì‚°
    4. ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    """

    # ì†Œìˆ˜ì  ì •ë°€ë„ ì„¤ì • (ëª¨ë“  ìˆ˜ì¹˜í˜• ë°ì´í„°ëŠ” ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ í‘œí˜„)
    DECIMAL_PRECISION = 1


    # ëª¨ë“  ê¸°í›„ ê´€ë ¨ ì²˜ë¦¬ì—ì„œ ì¼ê´€ë˜ê²Œ ì‚¬ìš©ë˜ëŠ” ì§€í‘œë“¤
    CLIMATE_METRICS = ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']


    # ì›ë³¸ ê¸°í›„ ë°ì´í„°ì˜ ì»¬ëŸ¼ëª…ì„ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    # ì—°ê°„('annual')ê³¼ ì›”ê°„('monthly') ë°ì´í„°ì˜ ì»¬ëŸ¼ëª…ì´ ì„œë¡œ ë‹¤ë¥´ë¯€ë¡œ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    CLIMATE_COLUMNS = {
        'annual': {
            'í‰ê· ê¸°ì˜¨(Â°C)í•©ê³„': 'í‰ê· ê¸°ì˜¨(Â°C)',
            'ê°•ìˆ˜ëŸ‰(mm)': 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)',
            'í‰ê·  ìƒëŒ€ìŠµë„(%)í•©ê³„': 'í‰ê·  ìƒëŒ€ìŠµë„(%)',
            'ì¼ì¡°ì‹œê°„(hr)': 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)'
        },
        'monthly': {
            'í‰ê· ê¸°ì˜¨(Â°C)': 'í‰ê· ê¸°ì˜¨(Â°C)',
            'í‰ê· ìƒëŒ€ìŠµë„(%)': 'í‰ê·  ìƒëŒ€ìŠµë„(%)',
            'ì›”í•©ê°•ìˆ˜ëŸ‰(00~24hë§Œ)(mm)': 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)',
            'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)': 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)'
        }
    }

    # ì§€ì—­ë³„ í–‰ì •êµ¬ì—­ ë§¤í•‘
    # ì§€ì ëª…ì„ ê´‘ì—­ì‹œë„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    # í‚¤: ì§€ì ëª…, ê°’: í•´ë‹¹ ì§€ì ì´ ì†í•œ ê´‘ì—­ì‹œë„
    REGION_MAPPING = {
        # ì „ë¼ë‚¨ë„ ì§€ì—­
        'ëª©í¬': 'ì „ë¼ë‚¨ë„', 'ì—¬ìˆ˜': 'ì „ë¼ë‚¨ë„', 'ìˆœì²œ': 'ì „ë¼ë‚¨ë„',
        'ì™„ë„': 'ì „ë¼ë‚¨ë„', 'ì§„ë„(ì²¨ì°°ì‚°)': 'ì „ë¼ë‚¨ë„', 'ì§„ë„êµ°': 'ì „ë¼ë‚¨ë„',
        'í•´ë‚¨': 'ì „ë¼ë‚¨ë„', 'ê³ í¥': 'ì „ë¼ë‚¨ë„', 'ê´‘ì–‘ì‹œ': 'ì „ë¼ë‚¨ë„',
        'ë³´ì„±êµ°': 'ì „ë¼ë‚¨ë„', 'ê°•ì§„êµ°': 'ì „ë¼ë‚¨ë„', 'ì¥í¥': 'ì „ë¼ë‚¨ë„',

        # ì¶©ì²­ë‚¨ë„ ì§€ì—­
        'ì„œì‚°': 'ì¶©ì²­ë‚¨ë„', 'ì²œì•ˆ': 'ì¶©ì²­ë‚¨ë„', 'ë³´ë ¹': 'ì¶©ì²­ë‚¨ë„',
        'ë¶€ì—¬': 'ì¶©ì²­ë‚¨ë„', 'í™ì„±': 'ì¶©ì²­ë‚¨ë„',

        # ì „ë¼ë¶ë„ ì§€ì—­
        'ì „ì£¼': 'ì „ë¼ë¶ë„', 'êµ°ì‚°': 'ì „ë¼ë¶ë„', 'ë¶€ì•ˆ': 'ì „ë¼ë¶ë„',
        'ì„ì‹¤': 'ì „ë¼ë¶ë„', 'ì •ì': 'ì „ë¼ë¶ë„', 'ë‚¨ì›': 'ì „ë¼ë¶ë„',
        'ì¥ìˆ˜': 'ì „ë¼ë¶ë„', 'ê³ ì°½êµ°': 'ì „ë¼ë¶ë„', 'ìˆœì°½êµ°': 'ì „ë¼ë¶ë„',

        # ê²½ìƒë¶ë„ ì§€ì—­
        'í¬í•­': 'ê²½ìƒë¶ë„', 'ì•ˆë™': 'ê²½ìƒë¶ë„', 'ìƒì£¼': 'ê²½ìƒë¶ë„',
        'ìš¸ì§„': 'ê²½ìƒë¶ë„', 'ë´‰í™”': 'ê²½ìƒë¶ë„', 'ì˜ì£¼': 'ê²½ìƒë¶ë„',
        'ë¬¸ê²½': 'ê²½ìƒë¶ë„', 'ì²­ì†¡êµ°': 'ê²½ìƒë¶ë„', 'ì˜ë•': 'ê²½ìƒë¶ë„',
        'ì˜ì„±': 'ê²½ìƒë¶ë„', 'êµ¬ë¯¸': 'ê²½ìƒë¶ë„', 'ì˜ì²œ': 'ê²½ìƒë¶ë„',
        'ê²½ì£¼ì‹œ': 'ê²½ìƒë¶ë„'
    }

    def __init__(self, target_regions: List[str]):
        self.target_regions = target_regions

    def _calculate_location_means(self, df: pd.DataFrame,group_by: str, columns: List[str], is_monthly: bool = False) -> Dict:
        """
        ì§€ì—­ë³„ í‰ê· ê°’ ê³„ì‚°

        Notes:
        - ì›”ë³„ ë°ì´í„°ì˜ ê²½ìš° ê° ì›”ë³„ë¡œ ê°œë³„ í‰ê·  ê³„ì‚°
        - íŠ¹ì • ì›”ì˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
        """
        if is_monthly:
            means = {}
            for col in columns:
                if col in df.columns:
                    monthly_means = {}
                    for month in range(1, 13):
                        month_data = df[df['ì¼ì‹œ'].str.endswith(f'-{month:02d}')][col]
                        monthly_means[month] = (
                            month_data.mean() if not month_data.empty
                            else df[col].mean()
                        )
                    means[col] = monthly_means
            return means
        else:
            return {
                col: df[col].mean()
                for col in columns
                if col in df.columns
            }

    def _sort_dataframe(self, df: pd.DataFrame, location_col: str) -> pd.DataFrame:
        """ë°ì´í„°í”„ë ˆì„ ì •ë ¬ì„ ìœ„í•œ í†µì¼ëœ ë©”ì„œë“œ"""
        return df.sort_values([location_col, 'ì¼ì‹œ']).reset_index(drop=True)

    def fill_missing_years(self, df: pd.DataFrame, start_year: int = 2008,
                          end_year: int = 2023) -> pd.DataFrame:
        """
        2008-2023ë…„ ë²”ìœ„ì˜ ëˆ„ë½ëœ ì—°ë„ ë°ì´í„°ë¥¼ ë³´ê°„í•˜ëŠ” í•¨ìˆ˜

        Args:
            df (pd.DataFrame): ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
            start_year (int): ì‹œì‘ ì—°ë„ (ê¸°ë³¸ê°’: 2008)
            end_year (int): ì¢…ë£Œ ì—°ë„ (ê¸°ë³¸ê°’: 2023)

        Returns:
            pd.DataFrame: ê²°ì¸¡ì¹˜ê°€ ë³´ê°„ëœ ë°ì´í„°í”„ë ˆì„

        ì²˜ë¦¬ ê³¼ì •:
        1. ê° ì§€ì—­ë³„ë¡œ ëˆ„ë½ëœ ì—°ë„/ì›” í™•ì¸
        2. í•´ë‹¹ ì§€ì—­ì˜ í‰ê· ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ëŒ€ì²´
        3. ì›”ë³„ ë°ì´í„°ì˜ ê²½ìš° ë™ì¼ ì›”ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´ (ê³„ì ˆì„± ê³ ë ¤)
        4. ë°ì´í„°ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ í‘œì¤€í™”

        Notes:
            - ì›”ë³„ ë°ì´í„°ì˜ ê²½ìš° YYYY-MM í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
            - ì—°ê°„ ë°ì´í„°ì˜ ê²½ìš° YYYY í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
            - ê²°ì¸¡ì¹˜ëŠ” í•´ë‹¹ ì§€ì—­ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
        """
        result_df = []
        is_monthly = isinstance(df['ì¼ì‹œ'].iloc[0], str) and '-' in str(df['ì¼ì‹œ'].iloc[0])

        for location in df['ì§€ì ëª…'].unique():  # ê° ì§€ì—­ë³„ë¡œ ë°˜ë³µ
            location_data = df[df['ì§€ì ëª…'] == location].copy()
            location_code = location_data['ì§€ì '].iloc[0]

            if is_monthly: # ì›”ë³„ ë°ì´í„° ì²˜ë¦¬
                existing_dates = location_data['ì¼ì‹œ'].unique()
                all_dates = [
                    f"{year}-{month:02d}"
                    for year in range(start_year, end_year + 1)
                    for month in range(1, 13)
                ]

                location_means = self._calculate_location_means( # ì§€ì—­ë³„ ì›”ë³„ í‰ê·  ê³„ì‚°
                    location_data, 'ì§€ì ëª…', self.CLIMATE_METRICS, is_monthly=True
                )

                missing_dates = [date for date in all_dates if date not in existing_dates] # ëˆ„ë½ëœ ë‚ ì§œ ì‹ë³„
                for date in missing_dates:
                    year, month = map(int, date.split('-')) # ë…„ì›” ë¶„ë¦¬
                    new_row = { # ìƒˆë¡œìš´ í–‰ ìƒì„±
                        'ì§€ì ': location_code,
                        'ì§€ì ëª…': location,
                        'ì¼ì‹œ': date,
                        **{col: location_means[col][month] # ì›”ë³„ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
                           for col in self.CLIMATE_METRICS
                           if col in location_data.columns}
                    }
                    result_df.append(new_row)
            else:  # ì—°ê°„ ë°ì´í„° ì²˜ë¦¬
                existing_years = location_data['ì¼ì‹œ'].astype(int).unique()
                all_years = list(range(start_year, end_year + 1))

                location_means = self._calculate_location_means( # ì§€ì—­ë³„ í‰ê·  ê³„ì‚°
                    location_data, 'ì§€ì ëª…', self.CLIMATE_METRICS
                )

                missing_years = [year for year in all_years if year not in existing_years] # ëˆ„ë½ ì—°ë„ ì‹ë³„
                for year in missing_years:
                    new_row = { # ìƒˆë¡œìš´ í–‰ ìƒì„±
                        'ì§€ì ': location_code,
                        'ì§€ì ëª…': location,
                        'ì¼ì‹œ': year,
                        **location_means # í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
                    }
                    result_df.append(new_row)

            result_df.extend(location_data.to_dict('records'))

        result_df = pd.DataFrame(result_df)
        result_df['ì§€ì '] = result_df['ì§€ì '].astype(int)

        result_df = self._sort_dataframe(result_df, 'ì§€ì ëª…')
        for col in self.CLIMATE_METRICS:
            if col in result_df.columns:
                result_df[col] = result_df[col].round(self.DECIMAL_PRECISION)

        return result_df

    def process_rice_data(self, file_path: Path, output_path: Optional[Path] = None) -> pd.DataFrame:
        """
        ìŒ€ ìƒì‚°ëŸ‰ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜

        ì²˜ë¦¬ ê³¼ì •:
        1. Excel íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        2. ì—°ë„ë³„ ì¬ë°°ë©´ì ê³¼ ìƒì‚°ëŸ‰ ë°ì´í„° ì¶”ì¶œ
        3. ë°ì´í„° ì¬êµ¬ì¡°í™” (Long formatìœ¼ë¡œ ë³€í™˜)
        4. ëŒ€ìƒ ì§€ì—­ í•„í„°ë§ ë° ì •ë ¬
        """
        try:
            raw_data = pd.read_excel(file_path)
        except Exception as e:
            raise ValueError(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")

        # ì—°ë„ ì»¬ëŸ¼ ì¶”ì¶œ (ìˆ«ìë¡œ ëœ ì»¬ëŸ¼ëª…ë§Œ ì„ íƒ)
        years = [int(col) for col in raw_data.columns[1:] if str(col).isdigit()]
        unique_years = sorted(set(years))

        # ë°ì´í„° ì¬êµ¬ì¡°í™”
        restructured_data = []
        for idx, row in raw_data.iloc[2:].iterrows():
            region_name = row.iloc[0]
            for i, year in enumerate(unique_years):
                # ê° ì—°ë„ë³„ë¡œ ì¬ë°°ë©´ì ê³¼ ìƒì‚°ëŸ‰ì´ 2ê°œ ì»¬ëŸ¼ì”© ì¡´ì¬
                area_idx = i * 2 + 1   # ì¬ë°°ë©´ì  ì»¬ëŸ¼ ì¸ë±ìŠ¤
                prod_idx = i * 2 + 2   # ìƒì‚°ëŸ‰ ì»¬ëŸ¼ ì¸ë±ìŠ¤

                try:
                    restructured_data.append({
                        'í–‰ì •êµ¬ì—­': region_name,
                        'ì¼ì‹œ': year,
                        'ì¬ë°°ë©´ì (ha)': row.iloc[area_idx],
                        'ìƒì‚°ëŸ‰(í†¤)': row.iloc[prod_idx]
                    })
                except (ValueError, IndexError):
                    continue

        # ëŒ€ìƒ ì§€ì—­ í•„í„°ë§ ë° ì •ë ¬
        processed_df = pd.DataFrame(restructured_data)
        processed_df = self._filter_and_sort_data(processed_df)

        if output_path:
            processed_df.to_excel(output_path, index=False)

        return processed_df

    def process_climate_data(
        self,
        annual_path: Path,
        monthly_path: Path
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ì—°ê°„/ì›”ê°„ ê¸°í›„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜

        ì²˜ë¦¬ ê³¼ì •:
        1. CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ (EUC-KR ì¸ì½”ë”©)
        2. ê²°ì¸¡ ì—°ë„/ì›” ë°ì´í„° ë³´ê°„
        3. ì»¬ëŸ¼ëª… í†µì¼ ë° í–‰ì •êµ¬ì—­ ì •ë³´ ì¶”ê°€
        4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì§€ì—­ë³„ í‰ê· ìœ¼ë¡œ ëŒ€ì²´)

        Notes:
            - ì—°ê°„/ì›”ê°„ ë°ì´í„°ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
            - CLIMATE_COLUMNS ë§¤í•‘ì„ í†µí•´ ì»¬ëŸ¼ëª… í†µì¼
            - ëª¨ë“  ìˆ˜ì¹˜ëŠ” ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ í‘œí˜„
        """
        annual_climate = pd.read_csv(annual_path, encoding='euc-kr')
        monthly_climate = pd.read_csv(monthly_path, encoding='euc-kr')

        annual_climate = self.fill_missing_years(annual_climate)
        monthly_climate = self.fill_missing_years(monthly_climate)

        annual_climate = self._prepare_climate_data(annual_climate, 'annual')
        monthly_climate = self._prepare_climate_data(monthly_climate, 'monthly')

        annual_climate = self.fill_missing_climate_data(annual_climate)
        monthly_climate = self.fill_missing_climate_data(monthly_climate)

        return annual_climate, monthly_climate

    def _filter_and_sort_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ë°ì´í„°í”„ë ˆì„ì„ í•„í„°ë§í•˜ê³  ì •ë ¬í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ

        Notes:
            - target_regionsì— í¬í•¨ëœ ì§€ì—­ë§Œ í•„í„°ë§
            - í–‰ì •êµ¬ì—­ê³¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        """
        if self.target_regions:
            df = df[df['í–‰ì •êµ¬ì—­'].isin(self.target_regions)]
        return self._sort_dataframe(df, 'í–‰ì •êµ¬ì—­')

    def _prepare_climate_data(self, df: pd.DataFrame, data_type: str) -> pd.DataFrame:
        """
        ê¸°í›„ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ ë©”ì„œë“œ

        ì²˜ë¦¬ ê³¼ì •:
        1. ì»¬ëŸ¼ëª…ì„ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
        2. ì§€ì ëª…ì„ í–‰ì •êµ¬ì—­ìœ¼ë¡œ ë§¤í•‘
        3. ëŒ€ìƒ ì§€ì—­ë§Œ í•„í„°ë§

        Notes:
            - CLIMATE_COLUMNS ë”•ì…”ë„ˆë¦¬ë¥¼ í†µí•´ ì»¬ëŸ¼ëª… ë³€í™˜
            - REGION_MAPPING ë”•ì…”ë„ˆë¦¬ë¥¼ í†µí•´ ì§€ì—­ ë§¤í•‘
        """
        df = df.rename(columns=self.CLIMATE_COLUMNS[data_type])
        df['í–‰ì •êµ¬ì—­'] = df['ì§€ì ëª…'].map(self.REGION_MAPPING)
        return df[df['í–‰ì •êµ¬ì—­'].isin(self.target_regions)]

    def fill_missing_climate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ê¸°í›„ ë°ì´í„°ì˜ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ

        ì²˜ë¦¬ ê³¼ì •:
        1. ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ë³€í™˜
        2. ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ê°’ì„ NaNìœ¼ë¡œ ì²˜ë¦¬
        3. ê° ì§€ì—­ë³„ í‰ê· ê°’ìœ¼ë¡œ NaN ëŒ€ì²´
        4. ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼

        Notes:
            - CLIMATE_METRICSì— ì •ì˜ëœ ì»¬ëŸ¼ë§Œ ì²˜ë¦¬
            - ì§€ì—­ë³„ë¡œ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ê²°ì¸¡ì¹˜ ëŒ€ì²´
            - ëª¨ë“  ìˆ˜ì¹˜ë¥¼ DECIMAL_PRECISION ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
        """
        df_filled = df.copy()

        for col in self.CLIMATE_METRICS:
            if col in df.columns:
                df_filled[col] = pd.to_numeric(
                    df_filled[col].replace('', np.nan),
                    errors='coerce'
                )
                region_means = (df_filled.groupby('í–‰ì •êµ¬ì—­')[col]
                              .transform('mean')
                              .round(self.DECIMAL_PRECISION))
                df_filled[col] = (df_filled[col]
                                .fillna(region_means)
                                .round(self.DECIMAL_PRECISION))
        return df_filled


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    rice_file = Path('/content/ì „êµ­_ì‹œêµ°ë³„_ë…¼ë²¼_ìƒì‚°ëŸ‰.xlsx')
    annual_climate_file = Path('/content/ì—°ê°„ê¸°í›„ì „ì²´ì§€ì—­.csv')
    monthly_climate_file = Path('/content/ì›”ë³„ê¸°í›„ì „ì²´ì§€ì—­.csv')

    # íƒ€ê²Ÿ ì§€ì—­ ì„¤ì •
    target_regions = ['ì „ë¼ë‚¨ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ê²½ìƒë¶ë„']

    # ë°ì´í„° í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    processor = DataProcessor(target_regions)

    try:
        # 1. ìŒ€ ìƒì‚°ëŸ‰ ë°ì´í„° ì²˜ë¦¬
        rice_data = processor.process_rice_data(
            rice_file,
            Path('filtered_rice_production.xlsx')
        )

        # 2. ê¸°í›„ ë°ì´í„° ì²˜ë¦¬
        annual_climate, monthly_climate = processor.process_climate_data(
            annual_climate_file,
            monthly_climate_file
        )

        # 3. ì²˜ë¦¬ëœ ê¸°í›„ ë°ì´í„° ì €ì¥
        annual_climate.to_csv('filtered_climate_annual_data.csv',
                            index=False, encoding='utf-8-sig')
        monthly_climate.to_csv('filtered_climate_monthly_data.csv',
                             index=False, encoding='utf-8-sig')

        print("ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    main()

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class RiceProductionAnalyzer:
    """ìŒ€ ìƒì‚°ëŸ‰ ë¶„ì„ì„ ìœ„í•œ í´ë˜ìŠ¤"""

    def __init__(self):
        """ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”"""
        print("\nğŸŒ¾ ìŒ€ ìƒì‚°ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
        self.rice_data = pd.read_excel('/content/filtered_rice_production.xlsx')
        self.climate_annual = pd.read_csv('/content/filtered_climate_annual_data.csv')
        self.climate_monthly = pd.read_csv('/content/filtered_climate_monthly_data.csv')
        self.processed_data = None
        self.region_colors = {
            'ì „ë¼ë‚¨ë„': '#1f77b4',  # íŒŒë€ìƒ‰
            'ì¶©ì²­ë‚¨ë„': '#2ca02c',  # ì´ˆë¡ìƒ‰
            'ì „ë¼ë¶ë„': '#ff7f0e',  # ì£¼í™©ìƒ‰
            'ê²½ìƒë¶ë„': '#d62728'   # ë¹¨ê°„ìƒ‰
        }
        print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n")
        self.prepare_data()

    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ë‚ ì§œ í˜•ì‹ í†µì¼
        self._unify_date_formats()
        # ì›”ë³„ ê¸°í›„ ë°ì´í„° í”¼ë´‡ ë° ë³‘í•©
        monthly_pivot = self._create_monthly_pivot()
        # ìµœì¢… ë°ì´í„° ë³‘í•©
        self._merge_all_data(monthly_pivot)

    def _unify_date_formats(self):
        """ë‚ ì§œ í˜•ì‹ í†µì¼í™”"""
        self.climate_annual['ì¼ì‹œ'] = self.climate_annual['ì¼ì‹œ'].astype(int)
        self.climate_monthly['ì—°ë„'] = self.climate_monthly['ì¼ì‹œ'].str.split('-').str[0].astype(int)
        self.climate_monthly['ì›”'] = self.climate_monthly['ì¼ì‹œ'].str.split('-').str[1].astype(int)

    def _create_monthly_pivot(self):
        """ì›”ë³„ ê¸°í›„ ë°ì´í„° í”¼ë´‡ í…Œì´ë¸” ìƒì„±"""
        pivot = self.climate_monthly.pivot_table(
            index=['í–‰ì •êµ¬ì—­', 'ì—°ë„'],
            columns='ì›”',
            values=['í‰ê· ê¸°ì˜¨(Â°C)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']
        ).reset_index()

        # ì»¬ëŸ¼ëª… ì¬êµ¬ì„±
        pivot.columns = [f"{col[0]}_{col[1]}ì›”" if isinstance(col, tuple) and col[1] != ""
                        else col[0] for col in pivot.columns]
        return pivot.rename(columns={'ì—°ë„': 'ì¼ì‹œ'})

    def _merge_all_data(self, monthly_pivot):
        """ëª¨ë“  ë°ì´í„° ë³‘í•©"""
        merged_data = pd.merge(
            self.rice_data,
            self.climate_annual[['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ', 'í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)',
                               'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']],
            on=['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ']
        )
        self.processed_data = pd.merge(merged_data, monthly_pivot, on=['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ'])

    def analyze_production_changes(self):
        """ìƒì‚°ëŸ‰ ë³€í™”ìœ¨ ë¶„ì„ ë° ì‹œê°í™”"""
        # ê¸°ì¤€ë…„ë„(2008) ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°
        self.rice_data['ë‹¨ìœ„ë©´ì ë‹¹ìƒì‚°ëŸ‰'] = (self.rice_data['ìƒì‚°ëŸ‰(í†¤)'] /
                                            self.rice_data['ì¬ë°°ë©´ì (ha)']).round(2)
        pivot_data = self.rice_data.pivot(index='ì¼ì‹œ', columns='í–‰ì •êµ¬ì—­', values='ë‹¨ìœ„ë©´ì ë‹¹ìƒì‚°ëŸ‰')
        change_ratio = (pivot_data / pivot_data.iloc[0] * 100 - 100).reset_index()
        base_production = pivot_data.iloc[0].round(2)

        # ë°ì´í„° ì¬êµ¬ì„±
        change_ratio_long = pd.melt(change_ratio,
                                  id_vars=['ì¼ì‹œ'],
                                  var_name='í–‰ì •êµ¬ì—­',
                                  value_name='ë³€í™”ìœ¨')

        # ë²”ë¡€ í…ìŠ¤íŠ¸ ìƒì„±
        custom_legend = {region: f"{region} (2008ë…„: {base_production[region]:,.2f}í†¤/ha)"
                        for region in pivot_data.columns}

        return self._create_production_change_plot(change_ratio_long, custom_legend)

    def _create_production_change_plot(self, data, custom_legend):
        """ìƒì‚°ëŸ‰ ë³€í™” ê·¸ë˜í”„ ìƒì„±"""
        fig = px.line(data,
                     x='ì¼ì‹œ',
                     y='ë³€í™”ìœ¨',
                     color='í–‰ì •êµ¬ì—­',
                     title='2008ë…„ ëŒ€ë¹„ ì§€ì—­ë³„ ìŒ€ ìƒì‚°ëŸ‰ ë³€í™”ìœ¨ (%)',
                     labels={'ë³€í™”ìœ¨': 'ë³€í™”ìœ¨ (%)', 'ì¼ì‹œ': 'ì—°ë„'},
                     markers=True,
                     color_discrete_map=self.region_colors)

        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
        for trace in fig.data:
            trace.name = custom_legend[trace.name]
            trace.line.width = 3
            trace.marker.size = 8

        fig.update_layout(
            height=600,
            width=1000,
            yaxis_tickformat='.1f',
            legend_title_text='ì§€ì—­ (2008ë…„ ê¸°ì¤€ ìƒì‚°ëŸ‰)',
            template='plotly_white',
            font=dict(family='Noto Sans KR', size=12),
            title=dict(font=dict(size=20, color='black'), x=0.5, y=0.95),
            legend=dict(yanchor="top", y=0.99, xanchor="right", x=0.99,
                       bgcolor='rgba(255, 255, 255, 0.8)'),
            plot_bgcolor='white',
            paper_bgcolor='white',
            xaxis=self._get_axis_style(),
            yaxis=self._get_axis_style()
        )
        return fig

    def _get_axis_style(self):
        """ì¶• ìŠ¤íƒ€ì¼ ì„¤ì •"""
        return dict(
            showgrid=True,
            gridwidth=1,
            gridcolor='lightgray',
            title_font=dict(size=14),
            tickfont=dict(size=12)
        )

    def analyze_regional_comparison(self):
        """ì§€ì—­ë³„ ìƒì‚° íŠ¹ì„± ë¹„êµ ë¶„ì„"""
        stats_df = self._calculate_regional_stats()
        return self._create_regional_comparison_plot(stats_df)

    def _calculate_regional_stats(self):
        """ì§€ì—­ë³„ í†µê³„ ê³„ì‚°"""
        stats_df = self.rice_data.groupby(['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ']).agg({
            'ì¬ë°°ë©´ì (ha)': 'sum',
            'ìƒì‚°ëŸ‰(í†¤)': 'sum'
        }).reset_index()
        stats_df['ë‹¨ìœ„ë©´ì ë‹¹ìƒì‚°ëŸ‰'] = (stats_df['ìƒì‚°ëŸ‰(í†¤)'] /
                                      stats_df['ì¬ë°°ë©´ì (ha)']).round(2)
        return stats_df

    def _create_regional_comparison_plot(self, stats_df):
        """ì§€ì—­ë³„ ë¹„êµ ê·¸ë˜í”„ ìƒì„±"""
        fig = make_subplots(
            rows=1, cols=3,
            subplot_titles=('ì§€ì—­ë³„ ì¬ë°°ë©´ì  (ha)',
                          'ì§€ì—­ë³„ ì´ ìƒì‚°ëŸ‰ (í†¤)',
                          'ì§€ì—­ë³„ ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰ (í†¤/ha)')
        )

        measures = ['ì¬ë°°ë©´ì (ha)', 'ìƒì‚°ëŸ‰(í†¤)', 'ë‹¨ìœ„ë©´ì ë‹¹ìƒì‚°ëŸ‰']
        for i, measure in enumerate(measures, 1):
            for region in stats_df['í–‰ì •êµ¬ì—­'].unique():
                region_data = stats_df[stats_df['í–‰ì •êµ¬ì—­'] == region]
                fig.add_trace(
                    go.Box(
                        y=region_data[measure],
                        name=region,
                        boxpoints='all',
                        pointpos=0,
                        marker_color=self.region_colors[region],
                        line_color=self.region_colors[region],
                        showlegend=(i == 1)
                    ),
                    row=1, col=i
                )

        fig.update_layout(
            height=600,
            width=1500,
            title_text="ì§€ì—­ë³„ ìŒ€ ìƒì‚° íŠ¹ì„± ë¹„êµ (2008-2023)",
            showlegend=True
        )

        for i, measure in enumerate(measures, 1):
            fig.update_yaxes(title_text=measure, row=1, col=i)

        return fig

    def analyze_climate_vulnerability(self):
        """ì§€ì—­ë³„ ê¸°í›„ ì·¨ì•½ì„± ë¶„ì„"""
        climate_vars = ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']
        vulnerability_metrics = {}

        for region in self.processed_data['í–‰ì •êµ¬ì—­'].unique():
            region_data = self.processed_data[self.processed_data['í–‰ì •êµ¬ì—­'] == region]

            # ê° ê¸°í›„ ë³€ìˆ˜ì˜ ë³€ë™ê³„ìˆ˜(CV) ê³„ì‚°
            cv_metrics = {}
            for var in climate_vars:
                cv = region_data[var].std() / region_data[var].mean()
                cv_metrics[f'{var}_CV'] = cv

            # ìƒì‚°ëŸ‰ ë³€ë™ì„±
            unit_production = region_data['ìƒì‚°ëŸ‰(í†¤)'] / region_data['ì¬ë°°ë©´ì (ha)']
            production_cv = unit_production.std() / unit_production.mean()
            cv_metrics['ë‹¨ìœ„ë©´ì ë‹¹ìƒì‚°ëŸ‰_CV'] = production_cv  # ì´ë¦„ë„ í•¨ê»˜ ë³€ê²½

            vulnerability_metrics[region] = cv_metrics

        vulnerability_df = pd.DataFrame(vulnerability_metrics).T

        # Plotly íˆíŠ¸ë§µ ìƒì„±
        fig = go.Figure(data=go.Heatmap(
            z=vulnerability_df.values,
            x=vulnerability_df.columns,
            y=vulnerability_df.index,
            text=np.round(vulnerability_df.values, 3),
            texttemplate='%{text}',
            textfont={"size": 10},
            hoverongaps=False,
            colorscale='YlOrRd',
            colorbar=dict(title='ë³€ë™ê³„ìˆ˜(CV)'),
        ))

        fig.update_layout(
            title='ì§€ì—­ë³„ ê¸°í›„ ì·¨ì•½ì„± ì§€í‘œ (ë³€ë™ê³„ìˆ˜ ê¸°ë°˜)',
            xaxis_title='ê¸°í›„ ë³€ìˆ˜',
            yaxis_title='ì§€ì—­',
            width=1000,
            height=600,
        )

        return fig, vulnerability_df

    def analyze_optimal_conditions(self):
        """ì§€ì—­ë³„ ìµœì  ì¬ë°° ì¡°ê±´ ë¶„ì„"""
        climate_vars = ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']
        optimal_conditions = {}

        for region in self.processed_data['í–‰ì •êµ¬ì—­'].unique():
            # ê° ì§€ì—­ë³„ë¡œ ìƒìœ„ 20% ë°ì´í„° ì¶”ì¶œ
            region_data = self.processed_data[self.processed_data['í–‰ì •êµ¬ì—­'] == region]
            threshold = region_data['ìƒì‚°ëŸ‰(í†¤)'].quantile(0.8)
            region_optimal = region_data[region_data['ìƒì‚°ëŸ‰(í†¤)'] >= threshold]

            conditions = {}
            for var in climate_vars:
                conditions[f'{var}_ë²”ìœ„'] = {
                    'ìµœì†Œ': region_optimal[var].min(),
                    'ìµœëŒ€': region_optimal[var].max(),
                    'í‰ê· ': region_optimal[var].mean()
                }

            optimal_conditions[region] = conditions

        fig = make_subplots(
            rows=1,
            cols=4,
            subplot_titles=[f'{var}' for var in climate_vars],
            horizontal_spacing=0.08
        )

        for idx, var in enumerate(climate_vars, 1):
            regions = []
            means = []
            mins = []
            maxs = []
            colors = []

            for region in optimal_conditions.keys():
                regions.append(region)
                means.append(optimal_conditions[region][f'{var}_ë²”ìœ„']['í‰ê· '])
                mins.append(optimal_conditions[region][f'{var}_ë²”ìœ„']['ìµœì†Œ'])
                maxs.append(optimal_conditions[region][f'{var}_ë²”ìœ„']['ìµœëŒ€'])
                colors.append(self.region_colors[region])

            fig.add_trace(
                go.Bar(
                    name=var,
                    y=regions,
                    x=means,
                    error_x=dict(
                        type='data',
                        symmetric=False,
                        array=[max-mean for max, mean in zip(maxs, means)],
                        arrayminus=[mean-min for min, mean in zip(mins, means)],
                        color='rgba(0,0,0,0.2)',
                        thickness=1.5,
                        width=10
                    ),
                    text=[f'{mean:.1f}' for mean in means],
                    textposition='auto',
                    marker=dict(
                        color=colors,
                        line=dict(width=1, color='#ffffff')
                    ),
                    showlegend=False,
                    orientation='h',
                    hovertemplate='%{y}' +
                                f'{var}: ' + '%{x:.1f}' +
                                'ìµœì†Œ: %{customdata[0]:.1f}' +
                                'ìµœëŒ€: %{customdata[1]:.1f}' +
                                '',
                    customdata=list(zip(mins, maxs))
                ),
                row=1,
                col=idx
            )

            fig.update_xaxes(
                title=dict(
                    text=var,
                    font=dict(size=12, color='#2c3e50')
                ),
                tickfont=dict(size=10),
                showgrid=True,
                gridwidth=1,
                gridcolor='rgba(189, 195, 199, 0.4)',
                row=1,
                col=idx
            )

            fig.update_yaxes(
                tickfont=dict(size=12, color='#2c3e50'),
                showgrid=False,
                row=1,
                col=idx
            )

        fig.update_layout(
            height=350,
            width=1500,
            title=dict(
                text='ì§€ì—­ë³„ ìµœì  ê¸°í›„ ì¡°ê±´ ë¶„ì„ (ìƒìœ„ 20% ìƒì‚°ëŸ‰ ê¸°ì¤€)',
                x=0.5,
                font=dict(size=20, color='#2c3e50', family='Noto Sans KR')
            ),
            showlegend=False,
            template='plotly_white',
            font=dict(family='Noto Sans KR'),
            plot_bgcolor='white',
            paper_bgcolor='white',
            margin=dict(t=100, b=50, l=50, r=50),
            bargap=0.2,
        )

        for i in fig['layout']['annotations']:
            i['font'] = dict(size=14, color='#2c3e50', family='Noto Sans KR')

        return fig, optimal_conditions

    def run_all_analyses(self):
        """ëª¨ë“  ë¶„ì„ ì‹¤í–‰"""
        print("1ï¸âƒ£ ìƒì‚°ëŸ‰ ë³€í™” ë¶„ì„")
        print("   ğŸ“ˆ 2008ë…„ ëŒ€ë¹„ ì§€ì—­ë³„ ìŒ€ ìƒì‚°ëŸ‰ ë³€í™”ìœ¨ì„ ë¶„ì„ì¤‘...")
        fig_changes = self.analyze_production_changes()
        fig_changes.show()

        print("2ï¸âƒ£ ì§€ì—­ë³„ ìƒì‚° íŠ¹ì„± ë¹„êµ")
        print("   ğŸ“Š ì¬ë°°ë©´ì , ìƒì‚°ëŸ‰, ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰ì„ ë¶„ì„ì¤‘...")
        fig_comparison = self.analyze_regional_comparison()
        fig_comparison.show()

        print("3ï¸âƒ£ ê¸°í›„ ì·¨ì•½ì„± ë¶„ì„")
        print("   ğŸŒ¡ï¸ ê¸°í›„ ë³€ìˆ˜ë³„ ì§€ì—­ ì·¨ì•½ì„±ì„ í‰ê°€ì¤‘...")
        fig_vulnerability, vulnerability_df = self.analyze_climate_vulnerability()
        fig_vulnerability.show()

        print("4ï¸âƒ£ ìµœì  ì¬ë°° ì¡°ê±´ ë¶„ì„")
        print("   ğŸ¯ ì§€ì—­ë³„ ìµœì  ê¸°í›„ ì¡°ê±´ì„ ë„ì¶œì¤‘...")
        fig_optimal, optimal_conditions = self.analyze_optimal_conditions()
        fig_optimal.show()

        print("="*50)
        print("ğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*50 + "\n")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\nğŸš€ ìŒ€ ìƒì‚°ëŸ‰ ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    analyzer = RiceProductionAnalyzer()
    analyzer.run_all_analyses()

if __name__ == "__main__":
    main()

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

class RiceProductionPredictor:
    def __init__(self):
        """ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸°í™”"""
        try:
            # ë°ì´í„° ë¡œë“œ
            self.rice_data = pd.read_excel('/content/filtered_rice_production.xlsx')
            self.climate_annual = pd.read_csv('/content/filtered_climate_annual_data.csv')
            self.climate_monthly = pd.read_csv('/content/filtered_climate_monthly_data.csv')

            self.processed_data = None
            self.model = None
            self.scaler = StandardScaler()
            self.feature_columns = None

        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    def prepare_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # ì—°ê°„ ê¸°í›„ ë°ì´í„° ì²˜ë¦¬ - ê° í–‰ì •êµ¬ì—­ë³„ í‰ê· 
            climate_annual_mean = self.climate_annual.groupby(['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ']).agg({
                'í‰ê· ê¸°ì˜¨(Â°C)': 'mean',
                'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)': 'sum',
                'í‰ê·  ìƒëŒ€ìŠµë„(%)': 'mean',
                'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)': 'mean'
            }).reset_index()

            # ì›”ë³„ ê¸°í›„ ë°ì´í„° ì²˜ë¦¬
            self.climate_monthly['ì—°ë„'] = self.climate_monthly['ì¼ì‹œ'].str.split('-').str[0].astype(int)
            self.climate_monthly['ì›”'] = self.climate_monthly['ì¼ì‹œ'].str.split('-').str[1].astype(int)

            # ì›”ë³„ ë°ì´í„° í”¼ë´‡ í…Œì´ë¸” ìƒì„± (í•œ ë²ˆì— í•˜ë‚˜ì˜ ì¸¡ì •ê°’ë§Œ ì²˜ë¦¬)
            pivot_dfs = []
            measures = ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']

            for measure in measures:
                pivot_df = pd.pivot_table(
                    self.climate_monthly,
                    values=measure,
                    index=['í–‰ì •êµ¬ì—­', 'ì—°ë„'],
                    columns='ì›”',
                    aggfunc='mean' if measure == 'í‰ê· ê¸°ì˜¨(Â°C)' or measure == 'í‰ê·  ìƒëŒ€ìŠµë„(%)' else 'sum'
                ).reset_index()

                # ì»¬ëŸ¼ëª… ë³€ê²½
                pivot_df.columns = [str(col) if isinstance(col, int) else col for col in pivot_df.columns]
                pivot_df.columns = [f"{measure}_{col}ì›”" if col.isdigit() else col for col in pivot_df.columns]

                pivot_dfs.append(pivot_df)

            # ëª¨ë“  í”¼ë²— í…Œì´ë¸” ë³‘í•©
            climate_monthly_pivot = pivot_dfs[0]
            for df in pivot_dfs[1:]:
                climate_monthly_pivot = pd.merge(
                    climate_monthly_pivot,
                    df,
                    on=['í–‰ì •êµ¬ì—­', 'ì—°ë„'],
                    how='inner'
                )

            # ì—°ë„ ì»¬ëŸ¼ëª… ë³€ê²½
            climate_monthly_pivot = climate_monthly_pivot.rename(columns={'ì—°ë„': 'ì¼ì‹œ'})

            # ë°ì´í„° ë³‘í•©
            merged_data = pd.merge(
                self.rice_data,
                climate_annual_mean,
                on=['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ'],
                how='left'
            )

            self.processed_data = pd.merge(
                merged_data,
                climate_monthly_pivot,
                on=['í–‰ì •êµ¬ì—­', 'ì¼ì‹œ'],
                how='left'
            )

            # ì´ì „ ì—°ë„ ë°ì´í„° ì¶”ê°€
            self.processed_data['ì´ì „ë…„ë„_ìƒì‚°ëŸ‰'] = self.processed_data.groupby('í–‰ì •êµ¬ì—­')['ìƒì‚°ëŸ‰(í†¤)'].shift(1)
            self.processed_data['ì´ì „ë…„ë„_ì¬ë°°ë©´ì '] = self.processed_data.groupby('í–‰ì •êµ¬ì—­')['ì¬ë°°ë©´ì (ha)'].shift(1)

            # ê²°ì¸¡ì¹˜ ì œê±°
            self.processed_data = self.processed_data.dropna()

            # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
            self.processed_data = pd.get_dummies(self.processed_data, columns=['í–‰ì •êµ¬ì—­'], prefix='ì§€ì—­')

            return self.processed_data

        except Exception as e:
            print(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("\ní˜„ì¬ ë°ì´í„° ìƒíƒœ:")
            print("ê¸°í›„ ì›”ë³„ ë°ì´í„° shape:", self.climate_monthly.shape)
            print("ê¸°í›„ ì—°ê°„ ë°ì´í„° shape:", climate_annual_mean.shape if 'climate_annual_mean' in locals() else "Not created")
            raise

    def train_model(self, target_year=2023):
          """ëª¨ë¸ í•™ìŠµ"""
          try:
              # ë°ì´í„° ì¤€ë¹„
              data = self.prepare_data()

              # í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
              train_data = data[data['ì¼ì‹œ'] < target_year]
              test_data = data[data['ì¼ì‹œ'] == target_year]

              if len(test_data) == 0:
                  raise ValueError(f"{target_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

              # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
              self.feature_columns = [col for col in data.columns
                                    if col not in ['ìƒì‚°ëŸ‰(í†¤)', 'ì¼ì‹œ']]
              X_train = train_data[self.feature_columns]
              y_train = train_data['ìƒì‚°ëŸ‰(í†¤)']
              X_test = test_data[self.feature_columns]
              y_test = test_data['ìƒì‚°ëŸ‰(í†¤)']

              # print("\ní•™ìŠµ ë°ì´í„° í¬ê¸°:", X_train.shape)
              # print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:", X_test.shape)

              # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
              X_train_scaled = self.scaler.fit_transform(X_train)
              X_test_scaled = self.scaler.transform(X_test)

              # ëª¨ë¸ í•™ìŠµ
              self.model = XGBRegressor(
                  n_estimators=100,
                  learning_rate=0.1,
                  max_depth=5,
                  random_state=42
              )
              self.model.fit(X_train_scaled, y_train)

              # ì˜ˆì¸¡ ë° í‰ê°€
              y_pred = self.model.predict(X_test_scaled)

              # í‰ê°€ ì§€í‘œ ê³„ì‚°
              mse = mean_squared_error(y_test, y_pred)
              rmse = np.sqrt(mse)
              r2 = r2_score(y_test, y_pred)
              mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

              # ì›ë³¸ ì§€ì—­ëª… ë³µì›
              region_columns = [col for col in test_data.columns if col.startswith('ì§€ì—­_')]
              region_mapping = test_data[region_columns].idxmax(axis=1).map(lambda x: x.replace('ì§€ì—­_', ''))

              # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
              results = pd.DataFrame({
                  'í–‰ì •êµ¬ì—­': region_mapping,
                  'ì‹¤ì œ_ìƒì‚°ëŸ‰': y_test,
                  'ì˜ˆì¸¡_ìƒì‚°ëŸ‰': y_pred,
                  'ì˜¤ì°¨': y_pred - y_test,
                  'ì˜¤ì°¨ìœ¨(%)': ((y_pred - y_test) / y_test) * 100
              })

              # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
              feature_importance = pd.DataFrame({
                  'feature': self.feature_columns,
                  'importance': self.model.feature_importances_
              }).sort_values('importance', ascending=False)

              return results, {'RMSE': rmse, 'R2': r2, 'MAPE': mape}, feature_importance

          except Exception as e:
              print(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
              raise

    def predict_future(self, future_year, scenario='trend'):
        """ìŒ€ ì¬ë°°ì‹œê¸°ë¥¼ ê³ ë ¤í•œ ë¯¸ë˜ ìƒì‚°ëŸ‰ ì˜ˆì¸¡"""
        try:
            if not self.model:
                raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € train_modelì„ ì‹¤í–‰í•˜ì„¸ìš”.")

            # ì¬ë°°ì‹œê¸°ë³„ ê¸°í›„ ë³€ìˆ˜ ê°€ì¤‘ì¹˜ ì •ì˜
            growing_seasons = {
                'ìœ¡ë¬˜ê¸°': {
                    'months': [3, 4],  # 3-4ì›”
                    'weight': 1.2,
                    'critical_vars': ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)']
                },
                'ëª¨ë‚´ê¸°': {
                    'months': [5],     # 5ì›”
                    'weight': 1.5,
                    'critical_vars': ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)']
                },
                'ìƒìœ¡ê¸°': {
                    'months': [6, 7, 8],  # 6-8ì›”
                    'weight': 1.3,
                    'critical_vars': ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']
                },
                'ì¶œìˆ˜ê¸°': {
                    'months': [8, 9],  # 8-9ì›”
                    'weight': 1.4,
                    'critical_vars': ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']
                },
                'ë“±ìˆ™ê¸°': {
                    'months': [9, 10],  # 9-10ì›”
                    'weight': 1.3,
                    'critical_vars': ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)']
                }
            }

            # ì§€ì—­ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            region_columns = [col for col in self.processed_data.columns if col.startswith('ì§€ì—­_')]
            regions = [col.replace('ì§€ì—­_', '') for col in region_columns]

            predictions = []

            for region in regions:
                # í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„°
                region_mask = self.processed_data[f'ì§€ì—­_{region}'] == 1
                region_data = self.processed_data[region_mask].copy()
                latest_data = region_data.iloc[-1:].copy()

                if len(latest_data) == 0:
                    print(f"ê²½ê³ : {region}ì˜ ìµœê·¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                latest_data['ì¼ì‹œ'] = future_year

                # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë°ì´í„° ì²˜ë¦¬ ì „ ê¸°í›„ ë³€ìˆ˜ ì»¬ëŸ¼ ëª©ë¡ ìƒì„±
                climate_cols = []
                for season_info in growing_seasons.values():
                    for var in season_info['critical_vars']:
                        for month in season_info['months']:
                            col = f"{var}_{month}ì›”"
                            if col in region_data.columns:
                                climate_cols.append(col)

                # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¸°í›„ ë°ì´í„° ì²˜ë¦¬
                if scenario == 'trend':
                    for col in climate_cols:
                        # ì—°ê°„ ì¶”ì„¸ ê³„ì‚° (ì°¨ìˆ˜ë¥¼ 2ë¡œ ì¦ê°€)
                        years = region_data['ì¼ì‹œ'].values
                        values = region_data[col].values
                        trend = np.polyfit(years, values, deg=2)
                        projected_value = np.polyval(trend, future_year)
                        latest_data[col] = projected_value

                elif scenario == 'worst':
                    for col in climate_cols:
                        if 'ê¸°ì˜¨' in col:
                            if any(str(m) in col for m in [6, 7, 8]):  # ìƒìœ¡ê¸° ê³ ì˜¨
                                latest_data[col] = region_data[col].max() * 1.2
                            else:
                                latest_data[col] = region_data[col].max() * 1.1
                        elif 'ê°•ìˆ˜ëŸ‰' in col:
                            if any(str(m) in col for m in [5]):  # ëª¨ë‚´ê¸°ì²  ê°€ë­„
                                latest_data[col] = region_data[col].min() * 0.7
                            elif any(str(m) in col for m in [9]):  # ìˆ˜í™•ê¸° ê°•ìš°
                                latest_data[col] = region_data[col].max() * 1.4
                            else:
                                latest_data[col] = region_data[col].quantile(0.9)
                        elif 'ì¼ì¡°ì‹œê°„' in col:
                            latest_data[col] = region_data[col].min() * 0.8
                        else:  # ìƒëŒ€ìŠµë„
                            latest_data[col] = region_data[col].max() * 1.2

                elif scenario == 'best':
                    # ìµœê·¼ 5ë…„ ì¤‘ ìµœê³  ìˆ˜í™•ëŸ‰ ë…„ë„ ì°¾ê¸°
                    recent_data = region_data.tail(5)
                    best_year = recent_data.loc[recent_data['ìƒì‚°ëŸ‰(í†¤)'].idxmax(), 'ì¼ì‹œ']
                    best_climate = recent_data[recent_data['ì¼ì‹œ'] == best_year]

                    for col in climate_cols:
                        optimal_value = best_climate[col].iloc[0]
                        # ìµœì  ì¡°ê±´ì— ì•½ê°„ì˜ ê°œì„ ì„ ê°€ì •
                        if 'ê¸°ì˜¨' in col:
                            latest_data[col] = optimal_value * 1.05
                        elif 'ê°•ìˆ˜ëŸ‰' in col:
                            latest_data[col] = optimal_value * 1.1
                        elif 'ì¼ì¡°ì‹œê°„' in col:
                            latest_data[col] = optimal_value * 1.15
                        else:  # ìƒëŒ€ìŠµë„
                            latest_data[col] = optimal_value * 1.02

                else:  # 'average' scenario
                    # ìµœê·¼ 3ë…„ í‰ê·  ì‚¬ìš©
                    recent_data = region_data.tail(3)
                    for col in climate_cols:
                        seasonal_adjustment = 1.0
                        if 'ê¸°ì˜¨' in col:
                            # ì›”ë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
                            month = int(col.split('_')[1].replace('ì›”', ''))
                            if month in [6, 7, 8]:  # ì—¬ë¦„ì² 
                                seasonal_adjustment = 1.1
                            elif month in [12, 1, 2]:  # ê²¨ìš¸ì² 
                                seasonal_adjustment = 0.9
                        latest_data[col] = recent_data[col].mean() * seasonal_adjustment

                # ì¬ë°°ë©´ì  ì¶”ì„¸ ë°˜ì˜ (2ì°¨ ë‹¤í•­ì‹ ì‚¬ìš©)
                years = region_data['ì¼ì‹œ'].values
                areas = region_data['ì¬ë°°ë©´ì (ha)'].values
                area_trend = np.polyfit(years, areas, deg=2)
                projected_area = max(0, np.polyval(area_trend, future_year))  # ìŒìˆ˜ ë°©ì§€
                latest_data['ì¬ë°°ë©´ì (ha)'] = projected_area

                # ì´ì „ ì—°ë„ ë°ì´í„° ì—…ë°ì´íŠ¸
                latest_data['ì´ì „ë…„ë„_ìƒì‚°ëŸ‰'] = region_data.iloc[-1]['ìƒì‚°ëŸ‰(í†¤)']
                latest_data['ì´ì „ë…„ë„_ì¬ë°°ë©´ì '] = region_data.iloc[-1]['ì¬ë°°ë©´ì (ha)']

                # ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„± ì„ íƒ ë° ìŠ¤ì¼€ì¼ë§
                X_future = latest_data[self.feature_columns]
                X_future_scaled = self.scaler.transform(X_future)
                pred = self.model.predict(X_future_scaled)[0]

                # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¶ˆí™•ì‹¤ì„± ë°˜ì˜)
                base_std = np.std(region_data['ìƒì‚°ëŸ‰(í†¤)']) / np.sqrt(len(region_data))
                scenario_uncertainty = {
                    'trend': 1.0,
                    'average': 1.2,
                    'worst': 1.5,
                    'best': 1.3
                }
                confidence_interval = 1.96 * base_std * scenario_uncertainty[scenario]

                predictions.append({
                    'í–‰ì •êµ¬ì—­': region,
                    'ì˜ˆì¸¡_ìƒì‚°ëŸ‰': pred,
                    'ì‹ ë¢°êµ¬ê°„_í•˜í•œ': max(0, pred - confidence_interval),
                    'ì‹ ë¢°êµ¬ê°„_ìƒí•œ': pred + confidence_interval,
                    'ì¬ë°°ë©´ì (ha)': latest_data['ì¬ë°°ë©´ì (ha)'].iloc[0]
                })

            results_df = pd.DataFrame(predictions)
            results_df['ë‹¨ìœ„ë©´ì ë‹¹_ìƒì‚°ëŸ‰'] = results_df['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] / results_df['ì¬ë°°ë©´ì (ha)']

            return results_df

        except Exception as e:
            print(f"ë¯¸ë˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    def evaluate_predictions(self, y_true, y_pred):
        """ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ í‰ê°€ ì§€í‘œ
            mse = mean_squared_error(y_true, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_true, y_pred)
            r2 = r2_score(y_true, y_pred)
            mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

            # Adjusted R2 ê³„ì‚°
            n = len(y_true)
            p = len(self.feature_columns)
            adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

            # ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„
            errors = y_true - y_pred
            mean_error = np.mean(errors)
            std_error = np.std(errors)

            # 95% ì‹ ë¢°êµ¬ê°„
            confidence_interval = 1.96 * std_error / np.sqrt(n)

            # ì •ê·œì„± ê²€ì •ì€ ìƒ˜í”Œ ìˆ˜ê°€ 8ê°œ ì´ìƒì¼ ë•Œë§Œ ìˆ˜í–‰
            if len(y_true) >= 8:
                _, normality_p_value = stats.normaltest(errors)
            else:
                # ìƒ˜í”Œ ìˆ˜ê°€ ì ì„ ë•ŒëŠ” ì •ê·œì„± ê°€ì •
                normality_p_value = 1.0

            return {
                'RMSE': rmse,
                'MAE': mae,
                'R2': r2,
                'Adjusted_R2': adjusted_r2,
                'MAPE': mape,
                'Mean_Error': mean_error,
                'Std_Error': std_error,
                'Confidence_Interval': confidence_interval,
                'Error_Normality_p_value': normality_p_value,
                'Sample_Size': len(y_true)
            }

        except Exception as e:
            print(f"í‰ê°€ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise

    def plot_growing_season_analysis(self, region=None):
        """ìƒìœ¡ì‹œê¸°ë³„ ê¸°í›„ ì˜í–¥ ì‹œê°í™”"""
        plt.style.use('seaborn')

        # ìƒìœ¡ì‹œê¸° ì •ì˜
        growing_seasons = {
            'ìœ¡ë¬˜ê¸°': [3, 4],
            'ëª¨ë‚´ê¸°': [5],
            'ìƒìœ¡ê¸°': [6, 7, 8],
            'ì¶œìˆ˜ê¸°': [8, 9],
            'ë“±ìˆ™ê¸°': [9, 10]
        }

        # ê¸°í›„ ë³€ìˆ˜
        climate_vars = ['í‰ê· ê¸°ì˜¨(Â°C)', 'í•©ê³„ ê°•ìˆ˜ëŸ‰(mm)', 'í‰ê·  ìƒëŒ€ìŠµë„(%)', 'í•©ê³„ ì¼ì¡°ì‹œê°„(hr)']

        fig = plt.figure(figsize=(20, 10))
        gs = fig.add_gridspec(2, 2)

        # 1. ìƒìœ¡ì‹œê¸°ë³„ ê¸°í›„ìš”ì†Œ ì˜í–¥ë„ íˆíŠ¸ë§µ
        ax1 = fig.add_subplot(gs[0, 0])
        impact_data = {}

        for season, months in growing_seasons.items():
            season_impact = {}
            for var in climate_vars:
                cols = [f"{var}_{m}ì›”" for m in months]
                correlation = np.abs(self.processed_data[cols].corrwith(self.processed_data['ìƒì‚°ëŸ‰(í†¤)'])).mean()
                season_impact[var] = correlation
            impact_data[season] = season_impact

        impact_df = pd.DataFrame(impact_data)
        sns.heatmap(impact_df, annot=True, cmap='YlOrRd', ax=ax1)
        ax1.set_title('ìƒìœ¡ì‹œê¸°ë³„ ê¸°í›„ìš”ì†Œ ì˜í–¥ë„')

        # 2. ì›”ë³„ ê¸°ì˜¨ ë³€í™” ì¶”ì´
        ax2 = fig.add_subplot(gs[0, 1])
        temp_cols = [col for col in self.processed_data.columns if 'í‰ê· ê¸°ì˜¨(Â°C)' in col and 'ì›”' in col]

        if region:
            region_data = self.processed_data[self.processed_data[f'ì§€ì—­_{region}'] == 1]
        else:
            region_data = self.processed_data

        months = range(1, 13)
        years = region_data['ì¼ì‹œ'].unique()[-5:]  # ìµœê·¼ 5ë…„

        for year in years:
            year_data = region_data[region_data['ì¼ì‹œ'] == year]
            temps = [year_data[f'í‰ê· ê¸°ì˜¨(Â°C)_{m}ì›”'].mean() for m in months]
            ax2.plot(months, temps, marker='o', label=str(year))

        ax2.set_xticks(months)
        ax2.set_xlabel('ì›”')
        ax2.set_ylabel('í‰ê·  ê¸°ì˜¨(Â°C)')
        ax2.set_title('ì›”ë³„ ê¸°ì˜¨ ë³€í™” ì¶”ì´ (ìµœê·¼ 5ë…„)')
        ax2.legend()
        ax2.grid(True)

        # 3. ê°•ìˆ˜ëŸ‰ ë¶„í¬ boxplot
        ax3 = fig.add_subplot(gs[1, 0])
        rain_cols = [col for col in self.processed_data.columns if 'ê°•ìˆ˜ëŸ‰' in col and 'ì›”' in col]
        rain_data = region_data[rain_cols].melt()
        sns.boxplot(x='variable', y='value', data=rain_data, ax=ax3)
        ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45)
        ax3.set_title('ì›”ë³„ ê°•ìˆ˜ëŸ‰ ë¶„í¬')

        # 4. ì¼ì¡°ì‹œê°„ê³¼ ìƒì‚°ëŸ‰ì˜ ê´€ê³„
        ax4 = fig.add_subplot(gs[1, 1])
        sun_cols = [col for col in self.processed_data.columns if 'ì¼ì¡°ì‹œê°„' in col and 'ì›”' in col]
        total_sun = region_data[sun_cols].sum(axis=1)
        ax4.scatter(total_sun, region_data['ìƒì‚°ëŸ‰(í†¤)'])
        ax4.set_xlabel('ì—°ê°„ ì´ ì¼ì¡°ì‹œê°„')
        ax4.set_ylabel('ìƒì‚°ëŸ‰(í†¤)')
        ax4.set_title('ì¼ì¡°ì‹œê°„ê³¼ ìƒì‚°ëŸ‰ì˜ ê´€ê³„')

        plt.tight_layout()
        plt.show()

    def plot_prediction_results(self, predictions_2024, predictions_2025, results_2023):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        plt.style.use('seaborn')

        # 1. ì‹œë‚˜ë¦¬ì˜¤ë³„ 2024ë…„ ì˜ˆì¸¡ ë¹„êµ
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))

        scenarios = ['trend', 'average', 'worst', 'best']
        colors = ['#2ecc71', '#3498db', '#e74c3c', '#f1c40f']

        for i, scenario in enumerate(scenarios):
            ax = axes[i//2, i%2]
            predictions = predictions_2024[scenario]

            x = np.arange(len(predictions['í–‰ì •êµ¬ì—­']))

            # ì˜ˆì¸¡ê°’ë§Œ í‘œì‹œ
            ax.bar(x, predictions['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'], color=colors[i], label='ì˜ˆì¸¡ ìƒì‚°ëŸ‰')

            # ì‹ ë¢°êµ¬ê°„ í‘œì‹œ
            ax.errorbar(x, predictions['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'],
                      yerr=[predictions['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] - predictions['ì‹ ë¢°êµ¬ê°„_í•˜í•œ'],
                            predictions['ì‹ ë¢°êµ¬ê°„_ìƒí•œ'] - predictions['ì˜ˆì¸¡_ìƒì‚°ëŸ‰']],
                      fmt='none', color='black', capsize=5)

            ax.set_xticks(x)
            ax.set_xticklabels(predictions['í–‰ì •êµ¬ì—­'])
            ax.set_title(f'{scenario.capitalize()} ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ ê²°ê³¼')
            ax.legend()

        plt.tight_layout()
        plt.show()

        # 2. 2023-2025 ì¶”ì„¸ ë¶„ì„
        plt.figure(figsize=(12, 8))

        for region in results_2023['í–‰ì •êµ¬ì—­'].unique():
            years = [2023, 2024, 2025]
            values = [
                results_2023[results_2023['í–‰ì •êµ¬ì—­'] == region]['ì‹¤ì œ_ìƒì‚°ëŸ‰'].iloc[0],  # 2023ë…„ì€ ì‹¤ì œê°’
                predictions_2024['trend'][predictions_2024['trend']['í–‰ì •êµ¬ì—­'] == region]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].iloc[0],  # 2024ë…„ ì˜ˆì¸¡ê°’
                predictions_2025[predictions_2025['í–‰ì •êµ¬ì—­'] == region]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].iloc[0]  # 2025ë…„ ì˜ˆì¸¡ê°’
            ]
            plt.plot(years, values, marker='o', linewidth=2, markersize=8, label=region)

        plt.title('ìŒ€ ìƒì‚°ëŸ‰ ì¶”ì„¸ ë¶„ì„ (2023-2025)', fontsize=14)
        plt.xlabel('ì—°ë„', fontsize=12)
        plt.ylabel('ìƒì‚°ëŸ‰(í†¤)', fontsize=12)
        plt.grid(True)
        plt.legend(fontsize=10)
        plt.tight_layout()
        plt.show()

        # 3. ì§€ì—­ë³„ ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰ ë¹„êµ
        plt.figure(figsize=(10, 6))
        for scenario in scenarios:
            data = predictions_2024[scenario]
            plt.plot(data['í–‰ì •êµ¬ì—­'], data['ë‹¨ìœ„ë©´ì ë‹¹_ìƒì‚°ëŸ‰'],
                    marker='o', label=scenario.capitalize())

        plt.title('ì‹œë‚˜ë¦¬ì˜¤ë³„ ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰ ë¹„êµ', fontsize=14)
        plt.xlabel('ì§€ì—­', fontsize=12)
        plt.ylabel('ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰(í†¤/ha)', fontsize=12)
        plt.xticks(rotation=45)
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.show()



def main():
    try:
        # ì‹œìŠ¤í…œ ì‹œì‘
        print("\n" + "="*70)
        print("                    ğŸŒ¾ ìŒ€ ìƒì‚°ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ğŸŒ¾")
        print("="*70)
        predictor = RiceProductionPredictor()

        # 2023ë…„ ì˜ˆì¸¡ ë° í‰ê°€
        print("\nğŸ“Š [2023ë…„ ìŒ€ ìƒì‚°ëŸ‰ ì˜ˆì¸¡ ë¶„ì„]")
        print("-"*70)
        results_2023, metrics, feature_importance = predictor.train_model(target_year=2023)

        # ìƒì„¸ í‰ê°€ ì§€í‘œ ê³„ì‚°
        detailed_metrics = predictor.evaluate_predictions(
            results_2023['ì‹¤ì œ_ìƒì‚°ëŸ‰'],
            results_2023['ì˜ˆì¸¡_ìƒì‚°ëŸ‰']
        )

        # ì§€ì—­ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“ ì§€ì—­ë³„ ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„")
        print("-" * 70)
        print("â€» ë‹¨ìœ„: í†¤")
        results_display = results_2023.copy()
        results_display['ì‹¤ì œ_ìƒì‚°ëŸ‰'] = results_display['ì‹¤ì œ_ìƒì‚°ëŸ‰'].apply(lambda x: f"{x:,.0f}")
        results_display['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] = results_display['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].apply(lambda x: f"{x:,.0f}")
        print(results_display)

        print("\nğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ:")
        print("-" * 70)
        metrics_df = pd.DataFrame([detailed_metrics]).round(4)
        print(metrics_df)

        print("\nğŸ” ì˜ˆì¸¡ ì •í™•ë„ ê²€ì¦:")
        print("-" * 70)
        print(f"ì‹ ë¢°ì„± ê²€ì • P-ê°’: {detailed_metrics['Error_Normality_p_value']:.4f}")
        if detailed_metrics['Error_Normality_p_value'] > 0.05:
            print("âœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ì— ì¼ë¶€ í¸í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ë¯¸ë˜ ì˜ˆì¸¡
        if detailed_metrics['R2'] > 0.7:
            print("\nğŸ”® ë¯¸ë˜ ìƒì‚°ëŸ‰ ì˜ˆì¸¡ ë¶„ì„ ì‹œì‘...")

            # ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ 2024ë…„ ì˜ˆì¸¡
            scenarios = ['trend', 'average', 'worst', 'best']
            scenario_names = {
                'trend': 'ì¶”ì„¸ ê¸°ë°˜',
                'average': 'í‰ê·  ê¸°í›„',
                'worst': 'ìµœì•… ê¸°í›„',
                'best': 'ìµœì  ê¸°í›„'
            }
            predictions_2024 = {}

            for scenario in scenarios:
                predictions_2024[scenario] = predictor.predict_future(2024, scenario=scenario)

                print(f"\nğŸ“Š 2024ë…„ ì˜ˆì¸¡ - {scenario_names[scenario]} ì‹œë‚˜ë¦¬ì˜¤")
                print("-" * 70)
                print("â€» ë‹¨ìœ„: í†¤")
                predictions_display = predictions_2024[scenario].copy()
                predictions_display['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] = predictions_display['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].apply(lambda x: f"{x:,.0f}")
                print(predictions_display.round(2))

                # ì‹ ë¢°êµ¬ê°„ ì‹œê°í™”
                plt.figure(figsize=(10, 6))
                plt.errorbar(
                    predictions_2024[scenario]['í–‰ì •êµ¬ì—­'],
                    predictions_2024[scenario]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'],
                    yerr=[
                        predictions_2024[scenario]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] - predictions_2024[scenario]['ì‹ ë¢°êµ¬ê°„_í•˜í•œ'],
                        predictions_2024[scenario]['ì‹ ë¢°êµ¬ê°„_ìƒí•œ'] - predictions_2024[scenario]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰']
                    ],
                    fmt='o'
                )
                plt.title(f'2024 ìƒì‚°ëŸ‰ ì˜ˆì¸¡ - {scenario.capitalize()} ì‹œë‚˜ë¦¬ì˜¤')
                plt.ylabel('ìƒì‚°ëŸ‰ (í†¤)')
                plt.xticks(rotation=45)
                plt.grid(True)
                plt.tight_layout()
                plt.show()

            # 2025ë…„ ì˜ˆì¸¡ (trend ì‹œë‚˜ë¦¬ì˜¤)
            predictions_2025 = predictor.predict_future(2025, scenario='trend')
            comparison_2025 = pd.merge(
                predictions_2025,
                predictions_2024['trend'][['í–‰ì •êµ¬ì—­', 'ì˜ˆì¸¡_ìƒì‚°ëŸ‰']].rename(
                    columns={'ì˜ˆì¸¡_ìƒì‚°ëŸ‰': '2024ë…„_ì˜ˆì¸¡'}
                ),
                on='í–‰ì •êµ¬ì—­'
            )
            comparison_2025['ë³€í™”ìœ¨(%)'] = (
                (comparison_2025['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'] - comparison_2025['2024ë…„_ì˜ˆì¸¡'])
                / comparison_2025['2024ë…„_ì˜ˆì¸¡'] * 100
            )

            print("\nğŸ”® 2025ë…„ ì¥ê¸° ì˜ˆì¸¡ ë¶„ì„ (ì¶”ì„¸ ê¸°ë°˜)")
            print("=" * 80)
            print("\nì§€ì—­ë³„ ì˜ˆì¸¡ ê²°ê³¼:")
            print("-" * 80)

            for idx, row in comparison_2025.iterrows():
                print(f"â–¶ {row['í–‰ì •êµ¬ì—­']}")
                print(f"   - 2025ë…„ ì˜ˆìƒ ìƒì‚°ëŸ‰: {row['ì˜ˆì¸¡_ìƒì‚°ëŸ‰']:>15,.0f} í†¤")
                print(f"   - 2024ë…„ ì˜ˆìƒ ìƒì‚°ëŸ‰: {row['2024ë…„_ì˜ˆì¸¡']:>15,.0f} í†¤")
                print(f"   - ì „ë…„ëŒ€ë¹„ ë³€í™”ìœ¨:    {row['ë³€í™”ìœ¨(%)']:>15.2f} %")
                print(f"   - ì¬ë°°ë©´ì :           {row['ì¬ë°°ë©´ì (ha)']:>15,.2f} ha")
                print(f"   - ë‹¨ìœ„ë©´ì ë‹¹ ìƒì‚°ëŸ‰:  {row['ë‹¨ìœ„ë©´ì ë‹¹_ìƒì‚°ëŸ‰']:>15.2f} í†¤/ha")
                print("-" * 80)


            # ì¶”ì„¸ ì‹œê°í™”
            plt.figure(figsize=(12, 6))
            for region in results_2023['í–‰ì •êµ¬ì—­'].unique():
                years = [2023, 2024, 2025]
                values = [
                    results_2023[results_2023['í–‰ì •êµ¬ì—­'] == region]['ì‹¤ì œ_ìƒì‚°ëŸ‰'].iloc[0],
                    predictions_2024['trend'][predictions_2024['trend']['í–‰ì •êµ¬ì—­'] == region]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].iloc[0],
                    predictions_2025[predictions_2025['í–‰ì •êµ¬ì—­'] == region]['ì˜ˆì¸¡_ìƒì‚°ëŸ‰'].iloc[0]
                ]
                plt.plot(years, values, marker='o', label=region)

            plt.title('ìŒ€ ìƒì‚°ëŸ‰ Trend 2023-2025')
            plt.xlabel('ì—°ë„')
            plt.ylabel('ìƒì‚°ëŸ‰ (í†¤)')
            plt.legend()
            plt.grid(True)
            plt.tight_layout()
            plt.show()

        else:
            print("\nâš ï¸ ê²½ê³ : ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„ê°€ ê¸°ì¤€ì¹˜(R2 > 0.7)ì— ë¯¸ë‹¬í•˜ì—¬ ë¯¸ë˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        raise

if __name__ == "__main__":
    main()